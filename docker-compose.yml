# SPDX-FileCopyrightText: 2019-2020 Magenta ApS
# SPDX-License-Identifier: MPL-2.0
version: "3.9"
services:
  # We use two images in development. One frontend that runs `vue-cli-service
  # serve`, named `frontend` and one that runs flask named `mo`. The frontend
  # image proxies requests to flask.

  # In production only the flask image is run. It will serve the production
  # ready frontend code, but the files are only updated on docker build.
  frontend:
    build:
      context: .
      dockerfile: docker/Dockerfile
      target: frontend
    environment:
      # `vue-cli-service serve` will proxy request to `/service` and `/saml`to
      # this endpoint. Defined in `frontend/vue.config.js`.
      - BASE_URL=http://mo:80
    # To reload on file changes, we mount the current folder into `/code`.
    # However we do not want node_modules on the host machine, so we create an
    # additional volume for it.
    volumes:
      - .:/app/
      - /app/frontend/node_modules
    depends_on:
      mo:
        condition: service_healthy
    ports:
      - "5001:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://frontend:8080"]
      interval: 5s
      timeout: 5s
      retries: 3
      start_period: 300s

  mo:
    build:
      context: .
      dockerfile: docker/Dockerfile
      target: dist
    # The `volumes` and `command` mounts the backend directory in the docker
    # container and overwrites the CMD from Dockerfile. With this gunicorn
    # reloads on file changes. This is very useful when developing the backend.
    # We also change the Flask app to one where a testing API for testcafe
    # e2e-tests is enabled.
    volumes:
      # Uncomment this with the path you would like to use for queries
      # - /tmp:/queries
      # For reload
      - ./backend:/app/backend
      - ./.pytest_cache:/app/.pytest_cache
    command: ["/start-reload.sh"]
    environment:
      AMQP_ENABLE: "true"

      DUMMY_MODE: "true"
      ENABLE_CORS: "true"
      ENVIRONMENT: development
      PYTHONASYNCIODEBUG: "1"

      CONF_DB_NAME: "mox"
      CONF_DB_USER: "mox"
      CONF_DB_PASSWORD: "mox"

      GRAPHQL_ENABLE: "true"
      GRAPHIQL_ENABLE: "true"

      LORA_URL: "http://mox/"

      OS2MO_LOG_LEVEL: "DEBUG"

      QUERY_EXPORT_DIR: "/queries"

      KEYCLOAK_SCHEMA: "http"
      KEYCLOAK_PORT: 8080
      KEYCLOAK_VERIFY_AUDIENCE: "false"

      JAEGER_HOSTNAME: "otel-collector"
      JAEGER_SERVICE: OS2mo
    ports:
      - "5000:80"
    depends_on:
      mox:
        condition: service_healthy
      msg_broker:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      otel-collector:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://mo:80/health/"]
      interval: 5s
      timeout: 5s
      retries: 3
      start_period: 300s

  mo-init:
    image: magentaaps/os2mo-init:0.2.1
    environment:
      AUTH_SERVER: "http://keycloak:8080/auth"
      MO_URL: "http://mo"
      CLIENT_ID: "dipex"
      CLIENT_SECRET: "603f1c82-d012-4d04-9382-dbe659c533fb"
      AUTH_REALM: "mo"
      LORA_URL: "http://mox"
      LORA_CLIENT_ID: "dipex"
      LORA_CLIENT_SECRET: "a091ed82-6e82-4efc-a8f0-001e2b127853"
      LORA_AUTH_REALM: "lora"
    #volumes:
    #  - type: bind
    #    source: ./init.config.yml
    #    target: /config/config.yml
    #    read_only: true
    depends_on:
      mo:
        condition: service_healthy
    profiles:
      - init

  mox:
    image: magentaaps/lora:3.1.1
    # build:
    #   context: ../lora
    #   dockerfile: docker/Dockerfile
    # command: '/start-reload.sh'
    environment:
      DB_HOST: mox-db
      DB_PASSWORD: mox
      DB_EXTENSIONS_PATH: "oio_rest/oio_rest/db_extensions/mo-01.json"

      MAX_WORKERS: "1"
      TESTING_API: "true"

      LORA_AUTH: "false"

      JAEGER_HOSTNAME: otel-collector
      JAEGER_SERVICE: LoRa
    ports:
      - "8080:80"
    depends_on:
      mox-db-init:
        condition: service_completed_successfully
      mox-db:
        condition: service_healthy
      otel-collector:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://mox:80/site-map"]
      interval: 5s
      timeout: 5s
      retries: 3
      start_period: 300s

  mox-db:
    image: postgres:11
    environment:
      POSTGRES_PASSWORD: mysecretpassword
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      interval: 5s
      timeout: 5s
      retries: 3
      start_period: 300s
    # The following will mount the database data directory to RAM. It
    # significantly speeds up the database at the cost of dataloss on shutdown.
    # This is useful for running tests, but should never be used if you want to
    # save the data.
    # tmpfs:
    #   - /var/lib/postgresql/data

  mox-db-init:
    image: magentaaps/postgres-os2mo:12.2-11.7-test
    # build:
    #   context: ../postgres-os2mo
    #   dockerfile: docker/Dockerfile
    environment:
      POSTGRES_HOST: mox-db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: mysecretpassword

      DB_NAME: mox
      DB_USER: mox
      DB_PASSWORD: mox
    depends_on:
      mox-db:
        condition: service_healthy

  msg_broker:
    # Normally, we expect the `rabbitmq` image. The -management images come
    # with a set of management plugins installed and enabled by default. They
    # can be accessed through the web interface on port 15672. The credentials
    # are guest/guest.
    image: rabbitmq:3-management
    # RabbitMQ stores data based on what it calls the "Node Name", which
    # defaults to the hostname. We set this, so we can keep track of our data.
    hostname: msg_broker
    # We expose the ports here, so decoupled agents can be developed with more
    # ease.
    ports:
      - "5672:5672"    # amqp port
      - "15672:15672"  # management port
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 5s
      timeout: 5s
      retries: 3
      start_period: 300s

  keycloak:
    image: quay.io/keycloak/keycloak:14.0.0
    command: [
      # The -b flag is important. It is the default CMD from the docker image. It
      # is passed to keycloak's standalone.sh. If it is not present, the service
      # will only bind to a single network interface. If there are multiple
      # interfaces, it appears to choose an interface at random, leading to subtle
      # breaking when the container is restarted and the interface on the
      # docker-compose network is not chosen.
      "-b", "0.0.0.0",
      "-Dkeycloak.migration.action=import",
      "-Dkeycloak.migration.provider=singleFile",
      "-Dkeycloak.migration.file=/srv/keycloak-realm.json"
    ]
    ports:
      - "8081:8080"
    environment:
      KEYCLOAK_USER: admin
      KEYCLOAK_PASSWORD: admin
      DB_VENDOR: POSTGRES
      DB_ADDR: "keycloak-db"
      DB_USER: keycloak
      DB_PASSWORD: keycloak
      DB_SCHEMA: public
      DB_DATABASE: keycloak
      # PROXY_ADDRESS_FORWARDING: 'true'
      # KEYCLOAK_FRONTEND_URL: https://proxy/auth
      # KEYCLOAK_LOGLEVEL: DEBUG
    depends_on:
      keycloak-gen:
        condition: service_completed_successfully
      keycloak-db:
        condition: service_healthy
    volumes:
      - keycloak-volume:/srv/:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://keycloak:8080/auth/"]
      interval: 5s
      timeout: 5s
      retries: 3
      start_period: 300s

  keycloak-gen:
    image: magentaaps/os2mo-keycloak-realm-builder:2.4.0
    environment:
      KEYCLOAK_VERSION: 14.0.0
      KEYCLOAK_SSL_REQUIRED_MO: external
      KEYCLOAK_SSL_REQUIRED_LORA: external
      KEYCLOAK_LORA_REALM_ENABLED: "true"
      KEYCLOAK_LORA_CLIENT_SECRET: 158a2075-aa8a-421c-94a4-2df35377014a
      KEYCLOAK_DIPEX_CLIENT_ENABLED: "true"
      KEYCLOAK_DIPEX_CLIENT_SECRET: "603f1c82-d012-4d04-9382-dbe659c533fb"
      KEYCLOAK_LORA_DIPEX_CLIENT_ENABLED: "true"
      KEYCLOAK_LORA_DIPEX_CLIENT_SECRET: "a091ed82-6e82-4efc-a8f0-001e2b127853"
      KEYCLOAK_MO_CLIENT_REDIRECT_URI: '["http://localhost:5000/*", "http://localhost:5001/*"]'
      KEYCLOAK_MO_CLIENT_WEB_ORIGIN: '["http://localhost:5000", "http://localhost:5001"]'
      KEYCLOAK_RBAC_ENABLED: "true"
      KEYCLOAK_REALM_USERS: '[
        {
          "username": "bruce",
          "password": "bruce",
          "firstname": "Bruce",
          "lastname": "Lee",
          "email": "bruce@kung.fu",
          "uuid": "99e7b256-7dfa-4ee8-95c6-e3abe82e236a",
          "enabled": true
        },
        {
          "username": "eline",
          "password": "eline",
          "firstname": "Eline",
          "lastname": "Wedsgaard Christensen",
          "email": "elinec@kolding.dk",
          "uuid": "1c571f8f-0e3e-4ffa-9ff0-d35505781924",
          "roles": ["owner"],
          "enabled": true
        },
        {
          "username": "alvida",
          "password": "alvida",
          "firstname": "Alvida",
          "lastname": "Nibe",
          "email": "alvidan@kolding.dk",
          "uuid": "0fb62199-cb9e-4083-ba45-2a63bfd142d7",
          "roles": ["admin"],
          "enabled": true
        },
        {
          "username": "anders",
          "password": "anders",
          "firstname": "Anders",
          "lastname": "And",
          "email": "anders@andeby.dk",
          "uuid": "53181ed2-f1de-4c4a-a8fd-ab358c2c454a",
          "roles": ["owner"],
          "enabled": true
        }
      ]'
    volumes:
      - keycloak-volume:/srv/

  keycloak-db:
    image: postgres:13.3
    environment:
      POSTGRES_DB: keycloak
      POSTGRES_USER: keycloak
      POSTGRES_PASSWORD: keycloak
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "keycloak"]
      interval: 5s
      timeout: 5s
      retries: 3
      start_period: 300s

  otel-collector:
    image: otel/opentelemetry-collector:0.31.0
    command: "--config /etc/otel-collector/config.yaml"
    volumes:
      - ./dev-environment/otel-config.yml:/etc/otel-collector/config.yaml
    depends_on:
      tempo:
        condition: service_healthy

  grafana:
    image: grafana/grafana
    volumes:
      - ./dev-environment/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yaml
    environment:  # Disables all auth - Skips login
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
    depends_on:
      tempo:
        condition: service_healthy
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://grafana:3000/api/health"]
      interval: 5s
      timeout: 5s
      retries: 3
      start_period: 300s

  tempo:
    image: grafana/tempo:latest
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
      - ./dev-environment/tempo.yml:/etc/tempo.yaml
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://tempo:3200/ready"]
      interval: 5s
      timeout: 5s
      retries: 3
      start_period: 300s

  fixture-loader:
    image: magentaaps/os2mo-kolding-fixture:latest
    environment:
      POSTGRES_HOST: mox-db
      POSTGRES_NAME: mox
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: mysecretpassword
    depends_on:
      mox-db-init:
        condition: service_completed_successfully
      mox-db:
        condition: service_healthy
    profiles:
      - kolding

  amqp-metrics:
    image: magentaaps/os2mo-amqp-trigger-metrics:latest
    environment:
      AMQP_HOST: msg_broker
      AMQP_PASSWORD: guest
    ports:
      - 8012:8000
    depends_on:
      mo:
        condition: service_healthy
      msg_broker:
        condition: service_healthy
    profiles:
      - amqp-metrics

  amqp-consumer:
    image: magentaaps/os2mo-amqp-trigger-example:latest
    environment:
      AMQP_HOST: msg_broker
      AMQP_PASSWORD: guest
      AMQP_ROUTING_KEYS: "*.*.*"
    depends_on:
      mo:
        condition: service_healthy
      msg_broker:
        condition: service_healthy
    profiles:
      - amqp-consumer

volumes:
  keycloak-volume:
